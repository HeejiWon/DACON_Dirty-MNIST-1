{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SsTW3i19K5cb",
    "outputId": "e16cf8c8-a31e-4ef5-9c55-9a93db487a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# 구글드라이브와 연동\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "YXQg1BQcNzID",
    "outputId": "148b4050-86f8-46c4-dba9-1dcb3c93ffc4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>k</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49997</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49998</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>49999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  a  b  c  d  e  f  g  h  i  j  ...  p  q  r  s  t  u  v  w  x  y  z\n",
       "0          0  1  1  0  1  0  1  0  0  0  0  ...  1  0  1  1  0  1  0  0  1  1  1\n",
       "1          1  0  1  0  1  1  0  0  1  1  1  ...  0  1  0  1  1  0  1  1  0  0  1\n",
       "2          2  1  0  1  0  1  1  1  0  0  0  ...  0  0  0  0  0  1  0  0  0  1  1\n",
       "3          3  0  1  1  1  0  0  0  1  1  1  ...  0  1  0  1  0  0  0  1  0  0  0\n",
       "4          4  1  1  1  0  0  0  1  0  1  0  ...  0  1  0  1  0  1  0  1  1  1  0\n",
       "...      ... .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. .. ..\n",
       "49995  49995  0  1  1  0  1  0  1  1  1  0  ...  1  0  1  1  1  0  0  0  0  0  1\n",
       "49996  49996  0  0  0  1  0  0  1  0  0  0  ...  1  0  1  1  0  1  0  1  1  1  1\n",
       "49997  49997  1  0  0  1  0  0  1  1  1  1  ...  1  0  1  0  1  1  1  0  0  0  1\n",
       "49998  49998  1  0  0  0  0  0  0  0  0  1  ...  0  1  1  1  1  1  0  1  1  0  0\n",
       "49999  49999  1  1  1  0  0  0  1  1  1  0  ...  0  1  0  0  1  0  0  0  0  1  1\n",
       "\n",
       "[50000 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# label 데이터셋 확인\n",
    "pd.read_csv(\"/content/drive/My Drive/project_dataset/dacon_m12/dirty_mnist_answer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQOFKAMa0dVd",
    "outputId": "0938823c-969a-4833-f429-aa5183a3ee85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/project_dataset/dacon_m12\n"
     ]
    }
   ],
   "source": [
    "# 구동 디렉토리 경로변경\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/project_dataset/dacon_m12')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcYBJqUg0rn3"
   },
   "outputs": [],
   "source": [
    "# # 현재 경로에 새로운 디렉토리 생성\n",
    "# # 생성한 디렉토리에 zip파일 압축해제\n",
    "# # 구글 드라이브가 맛탱이가 가서 재접속 할때마다 기존 폴더 삭제하고 다시 압축 풀어야함?\n",
    "\n",
    "from google.colab import output\n",
    "\n",
    "# 폴더 삭제하는 코드\n",
    "import shutil\n",
    "shutil.rmtree(\"dirty_mnist4\", ignore_errors=True)\n",
    "!mkdir \"dirty_mnist4\"\n",
    "!unzip \"dirty_mnist.zip\" -d \"dirty_mnist4\"\n",
    "\n",
    "# !mkdir \"./test_dirty_mnist\"\n",
    "# !unzip \"test_dirty_mnist.zip\" -d \"./test_dirty_mnist\"\n",
    "\n",
    "# !mkdir \"./mnist_origin\"\n",
    "# !unzip \"mnist_data.zip\" -d \"./mnist_origin\"\n",
    "\n",
    "output.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tlvn8ci5fH3F"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import  keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "c5pHIRSlngKt"
   },
   "outputs": [],
   "source": [
    "# 데이터가 존재하는 경로\n",
    "\n",
    "train_dir = \"/content/drive/MyDrive/project_dataset/dacon_m12/dirty_mnist3\"\n",
    "# len(os.listdir(\"/content/drive/MyDrive/project_dataset/dacon_m12/dirty_mnist3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vKQ1_qay9vng",
    "outputId": "f27859a6-1ca1-425d-e930-ec296d54942b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 3 invalid image filename(s) in x_col=\"index\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44998 validated image filenames.\n",
      "Found 5000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "meta_df = pd.read_csv('dirty_mnist_answer.csv')\n",
    "meta_df['index'] = meta_df['index'].apply(lambda x: str(\"{0:05d}\".format(x))+'.png')\n",
    "# meta_df['index'] = meta_df['index'].astype(\"str\").str.zfill(5) + '.png'\n",
    "columns = list(meta_df.columns[1:])\n",
    "\n",
    "\n",
    "# ImageDataGenerator 인스턴스 생성\n",
    "# Min-Max scaling - 추후 Standardization으로도 시도해볼까?\n",
    "datagen = ImageDataGenerator(rescale=1./255., validation_split=0.1)\n",
    "\n",
    "train_gen_1 = datagen.flow_from_dataframe(dataframe = meta_df,        # 메인 데이터프레임\n",
    "                                        directory = train_dir,        # 데이터 존재 경로\n",
    "                                        x_col='index',                # 이미지 파일이름 column 명\n",
    "                                        y_col=columns,                # 레이블들\n",
    "                                        batch_size=64,                # batch 크기 64 \n",
    "                                        seed=1,\n",
    "                                        color_mode = \"rgb\",           # RGB 사전훈련모델을 사용하기위해 rgb로 불러오기\n",
    "                                        class_mode='raw',\n",
    "                                        target_size=(256, 256),       # 이미지 shape 원본 그대로\n",
    "                                        subset='training')\n",
    "val_gen_1 = datagen.flow_from_dataframe(dataframe = meta_df,\n",
    "                                        directory = train_dir,\n",
    "                                        x_col='index',\n",
    "                                        y_col=columns,\n",
    "                                        batch_size=64,\n",
    "                                        seed=1,\n",
    "                                        color_mode = \"rgb\",\n",
    "                                        class_mode='raw',\n",
    "                                        target_size=(256, 256),\n",
    "                                        subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFUZ_UcJHJoZ",
    "outputId": "f15e6fdc-3f9f-4fea-e2e5-b284f0938061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 validated image filenames.\n",
      "Found 10000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_gen_2 = datagen.flow_from_dataframe(dataframe = meta_df,       \n",
    "                                        directory = train_dir,       \n",
    "                                        x_col='index',               \n",
    "                                        y_col=columns,               \n",
    "                                        batch_size=128,                     # 128\n",
    "                                        seed=1,\n",
    "                                        color_mode = \"grayscale\",           # grayscale\n",
    "                                        class_mode='raw',\n",
    "                                        target_size=(128, 128),             # 128, 128\n",
    "                                        subset='training')\n",
    "val_gen_2 = datagen.flow_from_dataframe(dataframe = meta_df,\n",
    "                                        directory = train_dir,\n",
    "                                        x_col='index',\n",
    "                                        y_col=columns,\n",
    "                                        batch_size=128,\n",
    "                                        seed=1,\n",
    "                                        color_mode = \"grayscale\",\n",
    "                                        class_mode='raw',\n",
    "                                        target_size=(128, 128),\n",
    "                                        subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdSRV4nTCpHM"
   },
   "source": [
    "# Xception freezing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwyR4vnMD5dr"
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyLRqL6YBeip",
    "outputId": "6a82ea2d-553c-4d12-92a3-76323371a769"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "704/704 [==============================] - 13672s 19s/step - loss: 0.6899 - accuracy: 0.0297 - val_loss: 0.6842 - val_accuracy: 0.0012\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.00120, saving model to ./dacon_m12/xception_all_freeze.h5\n",
      "Epoch 2/20\n",
      "704/704 [==============================] - 240s 341ms/step - loss: 0.6852 - accuracy: 0.0108 - val_loss: 0.6835 - val_accuracy: 0.0176\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.00120 to 0.01760, saving model to ./dacon_m12/xception_all_freeze.h5\n",
      "Epoch 3/20\n",
      "704/704 [==============================] - 250s 354ms/step - loss: 0.6844 - accuracy: 0.0067 - val_loss: 0.6840 - val_accuracy: 0.0284\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.01760 to 0.02840, saving model to ./dacon_m12/xception_all_freeze.h5\n",
      "Epoch 4/20\n",
      "704/704 [==============================] - 251s 357ms/step - loss: 0.6842 - accuracy: 0.0078 - val_loss: 0.6830 - val_accuracy: 8.0000e-04\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.02840\n",
      "Epoch 5/20\n",
      "704/704 [==============================] - 252s 357ms/step - loss: 0.6840 - accuracy: 0.0061 - val_loss: 0.6828 - val_accuracy: 0.0012\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.02840\n",
      "Epoch 6/20\n",
      "704/704 [==============================] - 252s 357ms/step - loss: 0.6838 - accuracy: 0.0068 - val_loss: 0.6829 - val_accuracy: 0.0054\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.02840\n",
      "Epoch 7/20\n",
      "704/704 [==============================] - 252s 357ms/step - loss: 0.6838 - accuracy: 0.0050 - val_loss: 0.6823 - val_accuracy: 0.0032\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.02840\n",
      "Epoch 8/20\n",
      "704/704 [==============================] - 251s 356ms/step - loss: 0.6835 - accuracy: 0.0048 - val_loss: 0.6825 - val_accuracy: 0.0010\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.02840\n",
      "Epoch 9/20\n",
      "704/704 [==============================] - 251s 357ms/step - loss: 0.6835 - accuracy: 0.0059 - val_loss: 0.6825 - val_accuracy: 0.0072\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.02840\n",
      "Epoch 10/20\n",
      "704/704 [==============================] - 252s 357ms/step - loss: 0.6835 - accuracy: 0.0069 - val_loss: 0.6825 - val_accuracy: 0.0114\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.02840\n",
      "Epoch 11/20\n",
      "704/704 [==============================] - 251s 357ms/step - loss: 0.6833 - accuracy: 0.0115 - val_loss: 0.6823 - val_accuracy: 0.0098\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.02840\n",
      "Epoch 12/20\n",
      "704/704 [==============================] - 251s 357ms/step - loss: 0.6831 - accuracy: 0.0129 - val_loss: 0.6824 - val_accuracy: 0.0024\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.02840\n",
      "Epoch 13/20\n",
      "704/704 [==============================] - 251s 357ms/step - loss: 0.6832 - accuracy: 0.0182 - val_loss: 0.6825 - val_accuracy: 0.0094\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.02840\n",
      "Epoch 14/20\n",
      "704/704 [==============================] - 252s 357ms/step - loss: 0.6833 - accuracy: 0.0064 - val_loss: 0.6821 - val_accuracy: 0.0018\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.02840\n",
      "Epoch 15/20\n",
      "704/704 [==============================] - 251s 357ms/step - loss: 0.6833 - accuracy: 0.0093 - val_loss: 0.6822 - val_accuracy: 0.0192\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.02840\n",
      "Epoch 16/20\n",
      "704/704 [==============================] - 251s 357ms/step - loss: 0.6831 - accuracy: 0.0109 - val_loss: 0.6824 - val_accuracy: 0.0104\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.02840\n",
      "Epoch 17/20\n",
      "704/704 [==============================] - 251s 357ms/step - loss: 0.6830 - accuracy: 0.0103 - val_loss: 0.6817 - val_accuracy: 0.0014\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.02840\n",
      "Epoch 18/20\n",
      "704/704 [==============================] - 251s 357ms/step - loss: 0.6830 - accuracy: 0.0115 - val_loss: 0.6819 - val_accuracy: 0.0022\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.02840\n",
      "Epoch 19/20\n",
      "704/704 [==============================] - 251s 357ms/step - loss: 0.6830 - accuracy: 0.0083 - val_loss: 0.6822 - val_accuracy: 0.0108\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.02840\n",
      "Epoch 20/20\n",
      "704/704 [==============================] - 252s 357ms/step - loss: 0.6833 - accuracy: 0.0178 - val_loss: 0.6821 - val_accuracy: 0.0032\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.02840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6fea834e10>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# candidate 1 - Xception\n",
    "\n",
    "base_model = keras.applications.xception.Xception(weights = \"imagenet\", \n",
    "                                                  include_top = False, \n",
    "                                                  input_shape = (256,256,3))\n",
    "\n",
    "# 모델 구조 확인 - 132층\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#     print(i, layer.name)\n",
    "\n",
    "# 모든 pre-trained 층 동결, 추가한 FC layer들만 학습 \n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "xcept = keras.Sequential([\n",
    "                          base_model,\n",
    "                          keras.layers.GlobalAveragePooling2D(),\n",
    "                          keras.layers.Dense(512, activation = 'relu'),\n",
    "                          keras.layers.Dropout(0.4),\n",
    "                          keras.layers.Dense(256, activation = 'relu'),\n",
    "                          keras.layers.Dropout(0.3),\n",
    "                          keras.layers.Dense(128, activation = 'relu'),\n",
    "                          keras.layers.Dropout(0.2),\n",
    "                          keras.layers.Dense(26, activation = \"sigmoid\", name='predictions')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "xcept.compile(optimizer = optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(f'./dacon_m12/xception_all_freeze.h5', monitor='val_accuracy', \n",
    "                                             save_best_only=True, verbose=1)\n",
    "early_stop_cb = keras.callbacks.EarlyStopping(patience = 7, restore_best_weights = True)\n",
    "\n",
    "\n",
    "xcept.fit_generator(generator = train_gen_1,\n",
    "                    epochs = 20,\n",
    "                    validation_data = val_gen_1,\n",
    "                    callbacks = [checkpoint, early_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nK0xMpxuF6OA"
   },
   "outputs": [],
   "source": [
    "# Freezing & Fine-tuning\n",
    "for layer in model.layers[:85]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[85:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "xcept.compile(optimizer = optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(f'./dacon_m12/xception_fine_tune_v1.h5', monitor='val_accuracy', \n",
    "                                             save_best_only=True, verbose=1)\n",
    "early_stop_cb = keras.callbacks.EarlyStopping(patience = 5, restore_best_weights = True)\n",
    "\n",
    "\n",
    "xcept.fit_generator(generator = train_gen_1,\n",
    "                    epochs = 10,\n",
    "                    validation_data = val_gen_1,\n",
    "                    callbacks = [checkpoint, early_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEFvkztLPNkn"
   },
   "outputs": [],
   "source": [
    "# candidate 2 - simple VGG\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "class SmallerVGGNet:\n",
    "    @staticmethod\n",
    "\t  def build(width, height, depth, classes, finalAct=\"sigmoid\"):\n",
    "\t\t    \n",
    "\t\t    model = Sequential()\n",
    "\t\t    inputShape = (256, 256, 3)\n",
    " \n",
    "        # CONV => RELU => POOL\n",
    "\t\t    model.add(Conv2D(32, (5, ), padding=\"same\",input_shape=inputShape))\n",
    "\t\t    model.add(Activation(\"relu\"))\n",
    "\t\t    model.add(BatchNormalization())\n",
    "\t\t    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\t\t    model.add(Dropout(0.25))\n",
    "        \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "    \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        # FC => RELU\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(finalAct))\n",
    "    \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOgC_1y-Rmwv"
   },
   "outputs": [],
   "source": [
    "model = SmallerVGGNet.build(\n",
    "\twidth=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
    "\tdepth=IMAGE_DIMS[2], classes=len(mlb.classes_),\n",
    "\tfinalAct=\"sigmoid\")\n",
    "\n",
    "# 옵티마이저 초기화\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    " \n",
    "# 네트워크 학습\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tepochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pIoSoNeGgrj"
   },
   "outputs": [],
   "source": [
    "# candidate 3 - resnet50v2\n",
    "\n",
    "resnet50v2 = keras.Sequential([\n",
    "                          keras.applications.ResNet50V2(weights = \"imagenet\", \n",
    "                                                               include_top = False, \n",
    "                                                               input_shape = (256,256,3)),\n",
    "                          keras.layers.GlobalAveragePooling2D(),\n",
    "                          keras.layers.Dense(256, activation = 'relu'),\n",
    "                          keras.layers.Dropout(0.3),\n",
    "                          keras.layers.Dense(128, activation = 'relu'),\n",
    "                          keras.layers.Dropout(0.2),\n",
    "                          keras.layers.Dense(26, activation = \"sigmoid\", name='predictions')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "resnet50v2.compile(optimizer = optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(f'./dacon_m12/m1_resnet50v2_0211.h5', monitor='val_accuracy', \n",
    "                                             save_best_only=True, verbose=1)\n",
    "early_stop_cb = keras.callbacks.EarlyStopping(patience = 5, restore_best_weights = True)\n",
    "\n",
    "\n",
    "resnet50v2.fit_generator(generator = train_gen_1,\n",
    "                    epochs = 10, \n",
    "                    validation_data = val_gen_1,\n",
    "                    callbacks = [checkpoint, early_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "UPUHN7kRs7NK",
    "outputId": "3868099b-35dc-4b5f-82c3-e1f0edbf4cc4"
   },
   "outputs": [],
   "source": [
    "# candidate 4 - My simple model\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Convolution2D, BatchNormalization, Flatten, Dense, Dropout,MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# ( Conv => BN => LReLU ) * 2 => pool / 2 \n",
    "model.add(Convolution2D(32, (7,7), padding='same', use_bias=False, input_shape=(128,128,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# ( Conv => BN => LReLU ) * 2 => pool / 2 \n",
    "model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# ( Conv => BN => LReLU ) * 2 => pool / 2 \n",
    "model.add(Convolution2D(128, (3,3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(Convolution2D(128, (3,3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(26, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "collapsed": true,
    "id": "UPUHN7kRs7NK",
    "outputId": "3868099b-35dc-4b5f-82c3-e1f0edbf4cc4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 77/313 [======>.......................] - ETA: 2:24:09 - loss: 1.5329 - accuracy: 0.0212"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-efd3488e666e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_gen_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                     callbacks = [checkpoint, early_stop_cb])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# complie\n",
    "opt = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "model.compile(optimizer = opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# callbacks\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(f'./dacon_m12/m1_simple.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "early_stop_cb = keras.callbacks.EarlyStopping(patience = 5, restore_best_weights = True)\n",
    "\n",
    "# fit\n",
    "model.fit_generator(generator = train_gen_2,\n",
    "                    epochs = 10,\n",
    "                    validation_data = val_gen_2,\n",
    "                    callbacks = [checkpoint, early_stop_cb])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "0210_Load_And_SimpleModel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
