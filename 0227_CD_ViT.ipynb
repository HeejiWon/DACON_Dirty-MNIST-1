{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0227_ViT",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPpHC1AIhg82+U6FV0Y5D22",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changdaeoh/DACON_Dirty-MNIST/blob/main/0227_ViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-esumtm4bWw",
        "outputId": "421b5ab9-901f-4d7f-b270-2af255425354"
      },
      "source": [
        "# 구글드라이브와 연동\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTQ3qzM84g9d",
        "outputId": "32b00b34-08ec-4846-ee16-60f4054d4e84"
      },
      "source": [
        "!pip install tensorflow_addons\r\n",
        "import tensorflow_addons as tfa\r\n",
        "\r\n",
        "# common modules\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import  keras\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd \r\n",
        "import random\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "import os\r\n",
        "os.chdir('/content/drive/MyDrive/project_dataset/dacon_v2')\r\n",
        "\r\n",
        "# 데이터 경로\r\n",
        "train_dir = \"/content/drive/MyDrive/project_dataset/dacon_v2/dirty_mnist_2nd\"\r\n",
        "test_dir = \"/content/drive/MyDrive/project_dataset/dacon_v2/test_route\"\r\n",
        "\r\n",
        "# GPU 확인\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "    raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))\r\n",
        "\r\n",
        "# global seed 고정\r\n",
        "SEED = 227\r\n",
        "\r\n",
        "def seed_everything(seed = 42):\r\n",
        "    random.seed(seed)\r\n",
        "    np.random.seed(seed)\r\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\r\n",
        "    tf.random.set_seed(seed)\r\n",
        "\r\n",
        "seed_everything(SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\r\u001b[K     |▌                               | 10kB 17.2MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 20.8MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30kB 24.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 40kB 21.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 51kB 16.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 61kB 15.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 71kB 14.4MB/s eta 0:00:01\r\u001b[K     |███▊                            | 81kB 14.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 92kB 13.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 102kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 112kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 122kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 133kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 143kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 153kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 163kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 174kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 184kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 194kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 204kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 215kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 225kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 235kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 245kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 256kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 266kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 276kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 286kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 296kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 307kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 317kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 327kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 337kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 348kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 358kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 368kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 378kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 389kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 399kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 409kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 419kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 430kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 440kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 450kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 460kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 471kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 481kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 491kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 501kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 512kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 522kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 532kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 542kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 552kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 563kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 573kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 583kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 593kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 604kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 614kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 624kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 634kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 645kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 655kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 665kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 675kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 686kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 696kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 706kB 13.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.12.1\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nLcwe4x4_Pi"
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5e48f7p56VJ"
      },
      "source": [
        "# Configure the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RghlGpAN5_B3"
      },
      "source": [
        "learning_rate = 0.001\r\n",
        "weight_decay = 0.0001\r\n",
        "batch_size = 128\r\n",
        "num_epochs = 100\r\n",
        "image_size = 72  # We'll resize input images to this size\r\n",
        "patch_size = 6  # Size of the patches to be extract from the input images\r\n",
        "num_patches = (image_size // patch_size) ** 2\r\n",
        "projection_dim = 64\r\n",
        "num_heads = 4\r\n",
        "transformer_units = [\r\n",
        "    projection_dim * 2,\r\n",
        "    projection_dim,\r\n",
        "]  # Size of the transformer layers\r\n",
        "transformer_layers = 8\r\n",
        "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWxM2_559xLc"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH55SW20-Dhj"
      },
      "source": [
        "num_classes = 26\r\n",
        "input_shape = (256, 256, 3)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmKAOhmF9t0R",
        "outputId": "18b43f89-b883-474f-bed3-f5ee17534ea3"
      },
      "source": [
        "meta_df = pd.read_csv('dirty_mnist_2nd_answer.csv')\r\n",
        "meta_df['index'] = meta_df['index'].apply(lambda x: str(\"{0:05d}\".format(x))+'.png')\r\n",
        "columns = list(meta_df.columns[1:])\r\n",
        "\r\n",
        "\r\n",
        "datagen = ImageDataGenerator(rescale=1./255.,\r\n",
        "                             rotation_range = 10,\r\n",
        "                             width_shift_range = 0.1,\r\n",
        "                             height_shift_range = 0.1,\r\n",
        "                             horizontal_flip = True,\r\n",
        "                             vertical_flip = True,\r\n",
        "                             validation_split = 0.1)\r\n",
        "\r\n",
        "# generator\r\n",
        "train_gen = datagen.flow_from_dataframe(dataframe = meta_df,        \r\n",
        "                                        directory = train_dir,       \r\n",
        "                                        x_col='index',               \r\n",
        "                                        y_col=columns,                \r\n",
        "                                        batch_size = batch_size,               \r\n",
        "                                        seed = SEED,\r\n",
        "                                        color_mode = \"rgb\",           \r\n",
        "                                        class_mode='raw',\r\n",
        "                                        target_size=(256, 256),       \r\n",
        "                                        subset='training')\r\n",
        "\r\n",
        "valid_gen = datagen.flow_from_dataframe(dataframe = meta_df,        \r\n",
        "                                        directory = train_dir,       \r\n",
        "                                        x_col='index',               \r\n",
        "                                        y_col=columns,                \r\n",
        "                                        batch_size = batch_size,               \r\n",
        "                                        seed = SEED,\r\n",
        "                                        color_mode = \"rgb\",           \r\n",
        "                                        class_mode='raw',\r\n",
        "                                        target_size=(256, 256),       \r\n",
        "                                        subset='validation')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 45000 validated image filenames.\n",
            "Found 5000 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0i4yHbhBojv"
      },
      "source": [
        "# Use data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8bohDj9Bmgi"
      },
      "source": [
        "data_augmentation = keras.Sequential(\r\n",
        "    [\r\n",
        "        # layers.experimental.preprocessing.Normalization(),\r\n",
        "        layers.experimental.preprocessing.Resizing(image_size, image_size)\r\n",
        "        # layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\r\n",
        "        # layers.experimental.preprocessing.RandomRotation(factor=0.02),\r\n",
        "        # layers.experimental.preprocessing.RandomZoom(\r\n",
        "        #     height_factor=0.2, width_factor=0.2\r\n",
        "        # ),\r\n",
        "    ],\r\n",
        "    name=\"data_augmentation\",\r\n",
        ")\r\n",
        "# Compute the mean and the variance of the training data for normalization.\r\n",
        "# data_augmentation.layers[0].adapt(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE2rKOMM6fL1"
      },
      "source": [
        "# Implement multilayer perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyYkxxkE6T8Z"
      },
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\r\n",
        "    for units in hidden_units:\r\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\r\n",
        "        x = layers.Dropout(dropout_rate)(x)\r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUog2DkU6xQE"
      },
      "source": [
        "# Implement patch creation as a layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuZx6kpZ6uTH"
      },
      "source": [
        "class Patches(layers.Layer):\r\n",
        "    def __init__(self, patch_size):\r\n",
        "        super(Patches, self).__init__()\r\n",
        "        self.patch_size = patch_size\r\n",
        "\r\n",
        "    def call(self, images):\r\n",
        "        batch_size = tf.shape(images)[0]\r\n",
        "        patches = tf.image.extract_patches(\r\n",
        "            images=images,\r\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\r\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\r\n",
        "            rates=[1, 1, 1, 1],\r\n",
        "            padding=\"VALID\",\r\n",
        "        )\r\n",
        "        patch_dims = patches.shape[-1]\r\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\r\n",
        "        return patches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OSzDp_n7TMq"
      },
      "source": [
        "# Implement the patch encoding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R80EwQ5y7U7-"
      },
      "source": [
        "class PatchEncoder(layers.Layer):\r\n",
        "    def __init__(self, num_patches, projection_dim):\r\n",
        "        super(PatchEncoder, self).__init__()\r\n",
        "        self.num_patches = num_patches\r\n",
        "        self.projection = layers.Dense(units=projection_dim)\r\n",
        "        self.position_embedding = layers.Embedding(\r\n",
        "            input_dim=num_patches, output_dim=projection_dim\r\n",
        "        )\r\n",
        "\r\n",
        "    def call(self, patch):\r\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\r\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\r\n",
        "        return encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q2fhuKZ7ZTX"
      },
      "source": [
        "# Build the ViT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTUKxJsA7gDG"
      },
      "source": [
        "def create_vit_classifier():\r\n",
        "    inputs = layers.Input(shape=input_shape)\r\n",
        "    # Augment data.\r\n",
        "    augmented = data_augmentation(inputs) \r\n",
        "\r\n",
        "    # Create patches.\r\n",
        "    patches = Patches(patch_size)(augmented)\r\n",
        "    # Encode patches.\r\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\r\n",
        "\r\n",
        "    # Create multiple layers of the Transformer block.\r\n",
        "    for _ in range(transformer_layers):\r\n",
        "        # Layer normalization 1.\r\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\r\n",
        "        # Create a multi-head attention layer.\r\n",
        "        attention_output = layers.MultiHeadAttention(\r\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\r\n",
        "        )(x1, x1)\r\n",
        "        # Skip connection 1.\r\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\r\n",
        "        # Layer normalization 2.\r\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\r\n",
        "        # MLP.\r\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\r\n",
        "        # Skip connection 2.\r\n",
        "        encoded_patches = layers.Add()([x3, x2])\r\n",
        "\r\n",
        "    # Create a [batch_size, projection_dim] tensor.\r\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\r\n",
        "    representation = layers.Flatten()(representation)\r\n",
        "    representation = layers.Dropout(0.5)(representation)\r\n",
        "    # Add MLP.\r\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\r\n",
        "    # Classify outputs.\r\n",
        "    logits = layers.Dense(num_classes)(features)\r\n",
        "    # Create the Keras model.\r\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2kXac697occ"
      },
      "source": [
        "# Compile, train, and evaluate the mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA0E7XR37vNX",
        "outputId": "52d81eb8-e193-4409-e276-1db3a7e93ac9"
      },
      "source": [
        "def run_experiment(model):\r\n",
        "    optimizer = tfa.optimizers.AdamW(\r\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\r\n",
        "    )\r\n",
        "\r\n",
        "    model.compile(\r\n",
        "        optimizer=optimizer,\r\n",
        "        loss=keras.losses.BinaryCrossentropy(from_logits=True),\r\n",
        "        metrics=[\r\n",
        "            keras.metrics.BinaryAccuracy(name='binary_accuracy')\r\n",
        "        ],\r\n",
        "    )\r\n",
        "\r\n",
        "    checkpoint_filepath = \"/model/ViT_vanilla_0227.h5\"\r\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\r\n",
        "        checkpoint_filepath,\r\n",
        "        monitor=\"val_binary_accuracy\",\r\n",
        "        save_best_only=True\r\n",
        "        # save_weights_only=True,\r\n",
        "    )\r\n",
        "\r\n",
        "    history = model.fit(\r\n",
        "        train_gen,\r\n",
        "        batch_size=batch_size,\r\n",
        "        epochs=num_epochs,\r\n",
        "        validation_data = valid_gen,\r\n",
        "        callbacks=[checkpoint_callback],\r\n",
        "    )\r\n",
        "\r\n",
        "    # model.load_weights(checkpoint_filepath)\r\n",
        "    # _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\r\n",
        "    # print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\r\n",
        "    # print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\r\n",
        "\r\n",
        "    return history\r\n",
        "\r\n",
        "\r\n",
        "vit_classifier = create_vit_classifier()\r\n",
        "history = run_experiment(vit_classifier)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "129/176 [====================>.........] - ETA: 1:29:47 - loss: 0.8479 - binary_accuracy: 0.5315"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}